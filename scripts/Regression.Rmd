---
title: "Регрессионный анализ"
author: "Evgenii Berdinskikh"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

library(broom)
library(car)
library(corrplot)
library(corrr)
library(factoextra)
library(forecast)
library(ggcorrplot)
library(GGally)
library(ggpubr)
library(ggbeeswarm)
library(lmtest)
library(MASS)
library(performance)
library(sandwich)
library(skimr)
library(tidyverse)
library(zoo)

theme_custom <- theme_bw()+ theme(
    plot.title = element_text(size = 30, hjust = 0.5),
    plot.subtitle = element_text(size = 25, hjust = 0.5),
    strip.text = element_text(size = 20),
    axis.text = element_text(size = 20),
    axis.title = element_text(size = 25),
    legend.title = element_text(size = 25),
    legend.text = element_text(size = 20)
  )
```

## Загрузка Tidy data для анализа

```{r read}

brain_data <- read_csv("../data/raw/brain_data.csv", show_col_types = FALSE) %>% 
  mutate( across( starts_with("Sud"), ~ as.factor(.) ) ) %>% 
  transmute(Date, Month = as.factor(month(Date)), Year = as.factor(year(Date)), 
            EMS, Wind, Temp_mean, H2O, Sunspots, Sud_Imp, Sud_Storm,
            Dst_mean, Dst_var = Dst_max - Dst_min, Dst_group = factor(case_when( 
              Dst_min < -150 ~ "level_5", Dst_min < -100 ~ "level_4",  
              Dst_min < -50 ~ "level_3",  Dst_min < -20 ~ "level_2",       
              TRUE ~ "level_1"), 
              levels = c("level_1", "level_2", "level_3", "level_4", "level_5"), 
              ordered = TRUE)
            )

Dst_pca <- read_fwf("../data/raw/WDC_Kyoto.dat",  
                          fwf_widths( c(3, 2, 2, 1, 2, 2, 1, 1, 2, 4, rep(4, 24), 4) ), 
                          show_col_types = FALSE) %>% 
  transmute(
    Date = as.Date(paste0(X9,X2,"-",X3,"-",X5)),
    across(X11:X34) %>%  set_names(paste0("H_", seq(1, 24) ))
    ) %>% 
  filter(Date %within% interval(min(brain_data$Date), max(brain_data$Date))) %>% 
  select(!Date) %>% scale() %>% prcomp()

brain_data_poisson <- brain_data %>% 
  bind_cols( as.tibble(Dst_pca$x) %>% select(PC1, PC2) )

##Локальное храненение данных 
write_csv(brain_data_poisson, "../data/raw/brain_data_poisson.csv") 

```


## Регрессия Пуассона 

```{r glm, fig.width=10}
model_glm <- glm(EMS ~ 
                   Date + 
                   Temp_mean +
                   # Wind +
                   # H2O +
                   Sunspots +
                   # Sud_Imp + Sud_Storm +
                   Dst_mean 
                   # Dst_var
                   # Dst_group 
                   # PC1 + PC2
                 , data = brain_data_poisson, family = poisson)

summary(model_glm)

#Стандартные ошибки
tidy(model_glm, conf.level = 0.95, conf.int = TRUE)

# plot(model_glm)
# check_model(model_glm)
# crPlots(model_glm)

```
## Регрессия Пуассона и робастные стандартные ошибки

```{r vcovHC}

#Робастные стандартные ошибки
bind_cols(
tidy( coeftest(model_glm, vcov. = vcovHC(model_glm, type = "HC3")) ), 
coefci(model_glm, vcov. = vcovHC(model_glm, type = "HC3")) %>% 
              as.tibble() %>% rename(conf.low = "2.5 %", conf.high = "97.5 %")) %>% 
  mutate(definition = exp(estimate))

```


## Отрицательное биномиальное распределение

```{r glm.nb, fig.width=10}

model_glm.nb <- glm.nb(EMS ~ 
                   Date + 
                   Temp_mean +
                   # Wind +
                   # H2O +
                   Sunspots +
                   # Sud_Imp + Sud_Storm +
                   Dst_mean 
                   # Dst_var
                   # Dst_group 
                   # PC1 + PC2
                 , data = brain_data_poisson, link = "log")

summary(model_glm.nb)
tidy(model_glm.nb, conf.level = 0.95, conf.int = TRUE)


# plot(model_glm.nb)

# check_model(model_glm)
# crPlots(model_glm.nb)

```

# Диагностика
Картинки - СЮДА!